% vim: set fenc=utf-8 ft=latex encoding=utf-8
% -*- mode: latex; coding: UTF-8; -*-
%!TEX root = knowledge-curation.tex
\section{Methodology}
\label{cha:methodology}

    We carried out a qualitative case study of the knowledge that flows through the channel. 
    This method is considered to be suitable for studies that explore under-researched phenomena and for providing an in-depth analysis within its real-life context~\cite{Yin2009}.

\subsection{Phase 1: Mining data archives} 
\label{sec:studyDesign}

	The mining of the data archives method involved a three step process: data collection, data analysis, and reporting.%~\cite{Runeson2012}.

\subsubsection{Data collection and preparation}
\label{subsec:preparation}

	Stack Overflow and the R-help mailing list store their messages in publicly available archives.
	The records available for Stack Overflow start in 2008 (the birth of Stack Overflow), while the R-help archives go back to 1997.
	To make both data sets comparable, we analysed the data from 2008 until 2013, a period of time that both channels were available simoultaneously.
    For Stack Overflow, we obtained a data dump file available in its website.
    For the R-help mailing list data, we retrieved the archives available as MBOX files from the R website.

	We used two different software tools to prepare the data.
	\begin{enumerate*}[label=(\arabic*)]
	\item to process the Stack Overflow data, we used a modified version of Sam Saffron's application, So-Slow\footnote{\url{https://github.com/SamSaffron/So-Slow}}; and,
	\item to process the R-help mailing list archives, we wrote a software application\footnote{Our tool is available at \url{https://github.com/cagomezt/GTMail}}, based on the Bettenburg \textit{et al}~\cite{Bettenburg2009} recommendations of how to process mailing list data.
	\end{enumerate*}
    Once we pre-processed the data, we stored them in a database for further analysis.

    To ensure accurate results when processing the R-help mailing list, we followed the series of recommendations proposed by Bettenburg \textit{et al}.~\cite{Bettenburg2009}.
    To make the data comparable againt the Stack Overflow dat set, we transformed the email addresses to MD5 hashes, and changed the time zone of the mailing list messages (UTC+2) to the time zone used by Stack Overflow (UTC).
    
    Stack Exchange releases a new data dump from all their websites every three months\footnote{\url{http://stackexchange.com/sites}}.
    However, the last dump file that containing email addresses as MD5 hashes was released in September 2013.
    Since then, Stack Overflow does not provide the email addresses.
    Because of this, we used the data dump file from September 2014, but updated the table \texttt{users} with the hashes in the dump file from September 2013, for whose \texttt{ID}s were identical in both data sets.
    If an user from the 2013 data file did not exist in the 2014 data, we ignored it.
    We filtered all R-related data by selecting only messages with the R tag (\texttt{r}) and its synonyms\footnote{\url{http://stackoverflow.com/tags/r/synonyms}} (\texttt{rstats} and \texttt{r-language}).

	Table~\ref{table:data} depicts a summary of the data uploaded in the database.
	The R-help has more questions, answers, and users than Stack Overflow, because there were approximately ten years of additional data.
	Only Stack Overflow's data contains ``comments'' information.

	\begin{table}[!htb]
	  \centering
      \caption{Raw data collected for each channel.}
      \begin{small}
        \begin{tabular}{lrr}
	        \toprule
	        Type          &  R-help & Stack Overflow \\
	        \midrule
	        Questions     & 101,931 &  67,393 \\
	        Answers       & 213,366 &  99,620 \\
	        Comments      &       - & 286,124 \\
	        Users         &  39,150 &  26,324 \\
	        \bottomrule
        \end{tabular}
      \end{small}
	  \label{table:data}
	\end{table}

    To merge both datasets, we matched Stack Overflow's email MD5 hashes with the MD5 hash version of email addresses from the R-help mailing list data.
    We did not use any method to infer email addresses based on user names.
    The resulting set was 1,421 different users with the same email address on both media channels.

    Although MD5 hashes are not \textit{collision resistant} and could possibly lead to false positives, it is unlikely that two different email addresses share a MD5 hash.

\subsubsection{Data analysis process}
\label{sec:dap}

    To analysis the data that flows through Stack Overflow and the R-help mailing list, we performed a qualitative and exploratory approach, as it best suits research when a concept or phenomenon requires more understanding, with little pre-existing research~\cite{Creswell2009}.
    
    In particular, we performed an inductive approach~\cite{Runeson2012} to analyse the data from Stack Overflow and the R-help mailing list.
    This is an iterative process, where across the study is necessary to switch between data selection and data analysis, or between data reporting and data collection.
    As advised to reduce bias~\cite{Runeson2012}, two researchers conducted the analysis, both computer scientists with a background in qualitative data analysis.
    
    \begin{figure*}[!htb]
    	\centering
    	\includegraphics[width=.9\textwidth]{Figures/CodingExample}
    	\caption{Example of data coding. Each row is a thread message. Questions, comments, and answers are identified with the number on the first column. Columns in yellow contain the codification for each message type. The last two columns contain the memos and the URL.}
    	\label{fig:CodingExample}
    \end{figure*}

    The techniques used to support the data analysis, which are explained as follow:

	\begin{description}[itemsep=3pt, topsep=2pt, leftmargin=3em, parsep=0pt]
		\item[Memoing] is the act of taking notes (coding) on what the researcher is learning from the data during the analysis~\cite{Groenewald2008}.
        We wrote reflective memos in a spreadsheet next to the applicable codes (see figure \ref{fig:CodingExample}).
        These memos were used to create the codes, and hypotheses about the relationships between concepts.

		\item[Affinity diagrams] allows to organize ideas and data into groups, and to find the relationships between concepts~\cite{Scupin1997}.
		We used them to discuss new insights, and while defining categories and relationships between them.

		\item[Inter-rater agreement \textit{Cohen Kappa}] is a coefficient used to measure the agreement between two coders who classify items into mutually exclusive categories~\cite{Stemler2004}.
		Ladis and Koch suggest that values above 0.60 or 60\% to obtain substantial results~\cite{Landis1977}.
		In a previous study~\cite{Gomez2013}, we used the same coefficient to measure agreement between coders.
		Based on this experience, we set a value above 0.80 or 80\% as the minimum to obtain substantial results.
		We used this coefficient after each coding session as a way to trigger discussion.

		\item[Code book] is a book that contains the definitions of the codes that researchers look during the data analysis~\cite{MacQueen1998}.
		We coded in multiple sessions, which allowed us to refine the definitions.
		Each entry is associated with a title, a formal definition, an example, and space for notes from the researcher.
		The final version of the code book is detailed in section~\ref{cha:findings}.
	\end{description}

	The focus of the analysis is to \textit{understand the context of the media channels and the community}.
	The process consisted of:
	First, a recollection of the official information for both channels and the community to build a background of the community of practice and the channels studied.
	Second, a mapping between messages from Stack Overflow with messages on the R-help mailing list.
    This is to overcome how the data is structured in both channels.
    The mapping of messages between both channels was as follows:

	\begin{description}[itemsep=3pt, topsep=2pt, leftmargin=3em, parsep=0pt]
		\item[Question:] the message is the first on the thread, and it contains the main question.
		\item[Answer:] the message provides a solution to the main question of the thread.
	 	\item[Update:] the message claims for a modification to a question (or answer) made by the author of such a question (or answer).
		\item[Comment:] the message offers a clarification to a specific part of the question or answer.
		\item[Flag:] the message requests attention from the moderator (e.g., repeated questions, spam, or rude behaviour).
	\end{description}

	To answer RQ1 and RQ2, we queried the database by selecting a random number of threads of each channels within a time frame.
	The data set was capped at 400 threads for each channel when we deemed our observations as being saturated.
	To answer RQ3, we added a condition that matched, on both channels, messages with the same subject written by the same author.
	The results were 79 threads, and therefore, we analysed the entire population available. 

\subsection{Phase 2: The survey} 

    In \textit{phase 2}, we conducted a survey\footnote{A copy of the survey is available at \url{http://goo.gl/mxmH5J}} with members of the R community with the purpose of obtaining additional insights on the findings.
    To test and refine the questions, format and tone, we performed two pilots.
    
    We announced our survey on Twitter, Reddit, the R-help mailing list, and Meta Stack Exchange to reach users of both channels, and minimize the selection bias.
    However, on Stack Exchange the announcement was not well received and therefore was deleted a few minutes later after posting it.
    We received 26 valid responses out of 32 from the R community members.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "knowledge-curation.tex"
%%% End:
